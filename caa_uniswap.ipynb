{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"id":"Lfa8O1udhLqJ"},"source":["### Pools\n","| Pair | Uniswap Pool | Binance Spot \n","| -----|--------------|----------------\n","| ETH/USDT|https://info.uniswap.org/#/pools/0x11b815efb8f581194ae79006d24e0d814b7697f6|https://www.binance.com/en/trade/ETH_USDT\n","| WBTC/USDT|https://info.uniswap.org/#/pools/0x9db9e0e53058c89e5b94e29621a205198648425b|https://www.binance.com/en/trade/BTC_USDT\n","| UNI/USDC |https://info.uniswap.org/#/pools/0xd0fc8ba7e267f2bc56044a7715a489d851dc6d78|https://www.binance.com/en/trade/UNI_USDT\n","\n","\n","\n","APIs: Binance: https://binance-docs.github.io/apidocs/spot/en/#kline-candlestick-data\n","\n","Web3: https://web3py.readthedocs.io/en/stable/web3.eth.html#web3.eth.Eth.get_logs\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["\n","**Before starting create config.yaml of following format:**\n","```\n","keys:\n","    infura_api : \"YOUR-API-KEY\"\n","```"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"2nbSldxVckhm"},"source":["# Get Uniswap Data"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["#### Imports"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"PEgSdz_htZ9r"},"outputs":[],"source":["import yaml\n","import traceback\n","import pandas as pd\n","from web3 import Web3\n","from eth_abi import abi"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"y2qnyOBL0P78"},"source":["#### Prepare W3 Connection"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1684505172919,"user":{"displayName":"Stephan Klein","userId":"12006621747936236229"},"user_tz":-120},"id":"yVHh2ky1zHAb","outputId":"efae39f5-d2c4-4f82-f53a-1d2cc4493a2d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Connect Successful\n"]}],"source":["with open('config.yaml') as f:\n","    config = yaml.load(f, Loader=yaml.FullLoader)\n","\n","def conETH(infura_api):\n","    # url link to the ethereum node\n","    url_eth_mainnet = \"https://mainnet.infura.io/v3/\"\n","    try:\n","        # connect to the ethereum node\n","        w3 = Web3(Web3.HTTPProvider(url_eth_mainnet + infura_api))\n","        return w3\n","    except:\n","        return None\n","\n","if config[\"keys\"][\"infura_api\"] is not None:\n","    w3 = conETH(config[\"keys\"][\"infura_api\"])\n","    # make the query\n","    if w3 is not None:\n","      print(\"Connect Successful\")\n","    else:\n","      print(\"Error: connection to the ethereum node failed\")\n","else:\n","    print(\"Error: infura api key not found\")"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"RPuIkR010d8y"},"source":["#### Reusable Methods"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"kec7GOeE0L_Z"},"outputs":[],"source":["SWAP_TOPIC = '0xc42079f94a6350d7e6235f29174924f928cc2ac818eb64fed8004e115fbcca67'\n","\n","def getLogs(start, nr, pool_addr):\n","  try:\n","    return w3.eth.get_logs({'fromBlock': start, 'toBlock': start+nr, 'address': w3.to_checksum_address(pool_addr)})\n","  except:\n","    traceback.print_exc()\n","    return None\n","\n","def decodeRow(row):\n","  decoded = abi.decode(['int256', 'int256', 'uint160', 'uint128', 'int24'], row['data'])\n","  row['amount0'] = decoded[0]\n","  row['amount1'] = decoded[1]\n","  row['sqrtPriceX96'] = decoded[2]\n","  row['txHash'] = row['transactionHash'].hex()\n","  # row['liquidity'] = decoded[3]\n","  # row['tick'] = decoded[4]\n","  return row\n","\n","def decode_hex_data_from_64b_log (hexstr):\n","    chunk_size = 64\n","    # Split the hex string into chunks of 32 bytes\n","    hex_chunks = [hexstr[i:i + chunk_size] for i in range(2, len(hexstr), chunk_size)]\n","    # Convert each chunk to decimal\n","    decimal_chunks = [float(chunk) for chunk in hex_chunks]\n","    return decimal_chunks\n","\n","def filter_and_decode(entries, pool_addr):\n","  df_logs = pd.DataFrame(entries)\n","  # Has the columns: Index(['address', 'blockHash', 'blockNumber', 'data', 'logIndex', 'removed', 'topics', 'transactionHash', 'transactionIndex']\n","\n","  print(\"Entries before address and topic filter:\",len(df_logs))\n","  # Retrieve lead topic and filter for address and swap event\n","  df_logs = df_logs.drop_duplicates(subset='blockNumber', keep='last')\n","  df_logs.loc[:, \"topic\"] = df_logs.topics.apply(lambda s: s[0].hex())\n","  df_logs1 = df_logs.loc[(df_logs[\"address\"].str.casefold() == pool_addr) & (df_logs[\"topic\"] == SWAP_TOPIC)]\n","  print(\"Entries after filters:\",len(df_logs1))\n","\n","  # Decode the log data\n","  df_logs1 = df_logs1.apply(decodeRow, axis=1)\n","  df_logs1 = df_logs1[['address', 'blockNumber', 'txHash','amount0','amount1','sqrtPriceX96']]\n","  #print(df_logs1)\n","  \n","  return df_logs1\n","\n","\n","def GetPrice(sqrtPriceX96, Decimal0, Decimal1):\n","    buyOneOfToken0 = ((sqrtPriceX96 / 2**96)**2) / (10**Decimal1 / 10**Decimal0)\n","\n","    return buyOneOfToken0\n","\n","    # buyOneOfToken1 = 1 / buyOneOfToken0\n","    # print(\"price of token0 in value of token1 : \" + str(buyOneOfToken0))\n","    # print(\"price of token1 in value of token0 : \" + str(buyOneOfToken1))\n","    # print(\"\")\n","    # # Convert to wei\n","    # buyOneOfToken0Wei = str(int(buyOneOfToken0 * (10**Decimal1)))\n","    # buyOneOfToken1Wei = str(int(buyOneOfToken1 * (10**Decimal0)))\n","    # print(\"price of token0 in value of token1 in lowest decimal : \" + buyOneOfToken0Wei)\n","    # print(\"price of token1 in value of token1 in lowest decimal : \" + buyOneOfToken1Wei)\n","    # print(\"\")'\n","def GetSwapPrice(amount0, amount1, Decimal0, Decimal1):\n","    buyOneOfToken0 = ((amount1 / 10**Decimal1) / (amount0 / 10**Decimal0)) * -1\n","\n","    return buyOneOfToken0\n","\n","def first(row):\n","    return row.iloc[0]\n","def last(row):\n","    return row.iloc[-1]"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":522},"executionInfo":{"elapsed":6130,"status":"ok","timestamp":1684505198706,"user":{"displayName":"Stephan Klein","userId":"12006621747936236229"},"user_tz":-120},"id":"II3BZvdv5n3R","outputId":"5bb6d264-99ef-4ae6-cd7b-2ca3cd711128"},"outputs":[],"source":["# Load Block Timestamps from CSV\n","timestamps = pd.read_csv('block_timestamps.csv')\n","\n","def extractPrices(logs, addr, decimal0, decimal1):\n","  swap_logs = filter_and_decode(logs, addr)\n","  # Merge Timestamps with Swap Log\n","  swap_logs = pd.merge(swap_logs, timestamps, left_on='blockNumber', right_on='number', how='left')\n","\n","  # Add datetime format timestamp\n","  swap_logs['datetime'] = pd.to_datetime(swap_logs['timestamp'], unit='s')\n","  swap_logs = swap_logs.set_index('datetime')\n","\n","  # Calculate Price of Token0 in Token1\n","  swap_logs['price'] = swap_logs['sqrtPriceX96'].apply(lambda price: GetPrice(price,decimal0,decimal1))\n","\n","  # Resample txHash\n","  candles = swap_logs.resample('1T').agg({'price': [('open','first'),('high','max'), ('low','min'), ('close','last')]})\n","  candles.columns = ['open','high','low','close']\n","\n","  # Forward Fill Close Price\n","  candles['close'].ffill(inplace=True)\n","\n","  # Cross Fill High and Low from Close Price\n","  candles['high'].fillna(candles['close'],inplace=True)\n","  candles['low'].fillna(candles['close'],inplace=True)\n","\n","  # Starting from second row, fill the open price with the previous close price\n","  candles.iloc[1:,0] = candles['close'].iloc[0:-1]\n","\n","  return candles\n","  # time_df"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"KEBXAl-pfy2f"},"source":["#### Process Data in Loop"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/","output_embedded_package_id":"18s-9J1TgOBvjEwSqJTQAkQ1h6Y80ylbT"},"executionInfo":{"elapsed":3799,"status":"ok","timestamp":1684505187671,"user":{"displayName":"Stephan Klein","userId":"12006621747936236229"},"user_tz":-120},"id":"MZY3YRNG8gCU","outputId":"aba77294-8944-4800-98de-c42da1d1c0af"},"outputs":[{"name":"stdout","output_type":"stream","text":["Getting logs from block 13916166 to 13966165\n","Received 95 tx logs\n","Entries before address and topic filter: 95\n","Entries after filters: 92\n","Getting logs from block 13966166 to 14016165\n","Received 70 tx logs\n","Entries before address and topic filter: 70\n","Entries after filters: 66\n","Getting logs from block 14016166 to 14066165\n","Received 220 tx logs\n","Entries before address and topic filter: 220\n","Entries after filters: 206\n","Getting logs from block 14066166 to 14116165\n","Received 147 tx logs\n","Entries before address and topic filter: 147\n","Entries after filters: 136\n","Getting logs from block 14116166 to 14166165\n","Received 297 tx logs\n","Entries before address and topic filter: 297\n","Entries after filters: 282\n","Getting logs from block 14166166 to 14216165\n","Received 226 tx logs\n","Entries before address and topic filter: 226\n","Entries after filters: 207\n","Getting logs from block 14216166 to 14266165\n","Received 90 tx logs\n","Entries before address and topic filter: 90\n","Entries after filters: 83\n","Getting logs from block 14266166 to 14316165\n","Received 193 tx logs\n","Entries before address and topic filter: 193\n","Entries after filters: 181\n","Getting logs from block 14316166 to 14366165\n","Received 85 tx logs\n","Entries before address and topic filter: 85\n","Entries after filters: 71\n","Getting logs from block 14366166 to 14416165\n","Received 124 tx logs\n","Entries before address and topic filter: 124\n","Entries after filters: 105\n","Getting logs from block 14416166 to 14466165\n","Received 320 tx logs\n","Entries before address and topic filter: 320\n","Entries after filters: 305\n","Getting logs from block 14466166 to 14516165\n","Received 405 tx logs\n","Entries before address and topic filter: 405\n","Entries after filters: 372\n","Getting logs from block 14516166 to 14566165\n","Received 152 tx logs\n","Entries before address and topic filter: 152\n","Entries after filters: 139\n","Getting logs from block 14566166 to 14616165\n","Received 138 tx logs\n","Entries before address and topic filter: 138\n","Entries after filters: 131\n","Getting logs from block 14616166 to 14666165\n","Received 144 tx logs\n","Entries before address and topic filter: 144\n","Entries after filters: 134\n","Getting logs from block 14666166 to 14716165\n","Received 177 tx logs\n","Entries before address and topic filter: 177\n","Entries after filters: 166\n","Getting logs from block 14716166 to 14766165\n","Received 323 tx logs\n","Entries before address and topic filter: 323\n","Entries after filters: 293\n","Getting logs from block 14766166 to 14816165\n","Received 841 tx logs\n","Entries before address and topic filter: 841\n","Entries after filters: 798\n","Getting logs from block 14816166 to 14866165\n","Received 930 tx logs\n","Entries before address and topic filter: 930\n","Entries after filters: 895\n","Getting logs from block 14866166 to 14916165\n","Received 632 tx logs\n","Entries before address and topic filter: 632\n","Entries after filters: 612\n","Getting logs from block 14916166 to 14966165\n","Received 383 tx logs\n","Entries before address and topic filter: 383\n","Entries after filters: 368\n","Getting logs from block 14966166 to 15016165\n","Received 1036 tx logs\n","Entries before address and topic filter: 1036\n","Entries after filters: 940\n","Getting logs from block 15016166 to 15066165\n","Received 1680 tx logs\n","Entries before address and topic filter: 1680\n","Entries after filters: 1613\n","Getting logs from block 15066166 to 15116165\n","Received 1152 tx logs\n","Entries before address and topic filter: 1152\n","Entries after filters: 1099\n","Getting logs from block 15116166 to 15166165\n","Received 1469 tx logs\n","Entries before address and topic filter: 1469\n","Entries after filters: 1392\n","Getting logs from block 15166166 to 15216165\n","Received 656 tx logs\n","Entries before address and topic filter: 656\n","Entries after filters: 613\n","Getting logs from block 15216166 to 15266165\n","Received 654 tx logs\n","Entries before address and topic filter: 654\n","Entries after filters: 605\n","Getting logs from block 15266166 to 15316165\n","Received 357 tx logs\n","Entries before address and topic filter: 357\n","Entries after filters: 322\n","Getting logs from block 15316166 to 15366165\n","Received 303 tx logs\n","Entries before address and topic filter: 303\n","Entries after filters: 283\n","Getting logs from block 15366166 to 15416165\n","Received 307 tx logs\n","Entries before address and topic filter: 307\n","Entries after filters: 292\n","Getting logs from block 15416166 to 15466165\n","Received 225 tx logs\n","Entries before address and topic filter: 225\n","Entries after filters: 212\n","Getting logs from block 15466166 to 15516165\n","Received 236 tx logs\n","Entries before address and topic filter: 236\n","Entries after filters: 212\n","Getting logs from block 15516166 to 15566165\n","Received 345 tx logs\n","Entries before address and topic filter: 345\n","Entries after filters: 331\n","Getting logs from block 15566166 to 15616165\n","Received 413 tx logs\n","Entries before address and topic filter: 413\n","Entries after filters: 381\n","Getting logs from block 15616166 to 15666165\n","Received 542 tx logs\n","Entries before address and topic filter: 542\n","Entries after filters: 469\n","Getting logs from block 15666166 to 15716165\n","Received 361 tx logs\n","Entries before address and topic filter: 361\n","Entries after filters: 312\n","Getting logs from block 15716166 to 15766165\n","Received 373 tx logs\n","Entries before address and topic filter: 373\n","Entries after filters: 333\n","Getting logs from block 15766166 to 15816165\n","Received 378 tx logs\n","Entries before address and topic filter: 378\n","Entries after filters: 358\n","Getting logs from block 15816166 to 15866165\n","Received 604 tx logs\n","Entries before address and topic filter: 604\n","Entries after filters: 560\n","Getting logs from block 15866166 to 15916165\n","Received 498 tx logs\n","Entries before address and topic filter: 498\n","Entries after filters: 462\n","Getting logs from block 15916166 to 15966165\n","Received 1102 tx logs\n","Entries before address and topic filter: 1102\n","Entries after filters: 1036\n","Getting logs from block 15966166 to 16016165\n","Received 532 tx logs\n","Entries before address and topic filter: 532\n","Entries after filters: 491\n","Getting logs from block 16016166 to 16066165\n","Received 389 tx logs\n","Entries before address and topic filter: 389\n","Entries after filters: 367\n","Getting logs from block 16066166 to 16116165\n","Received 676 tx logs\n","Entries before address and topic filter: 676\n","Entries after filters: 652\n","Getting logs from block 16116166 to 16166165\n","Received 200 tx logs\n","Entries before address and topic filter: 200\n","Entries after filters: 180\n","Getting logs from block 16166166 to 16216165\n","Received 276 tx logs\n","Entries before address and topic filter: 276\n","Entries after filters: 250\n","Getting logs from block 16216166 to 16266165\n","Received 196 tx logs\n","Entries before address and topic filter: 196\n","Entries after filters: 177\n","Getting logs from block 16266166 to 16308189\n","Received 156 tx logs\n","Entries before address and topic filter: 156\n","Entries after filters: 148\n"]}],"source":["# SYMBOL = \"WETH_USDT\"\n","# POOL_ADDR = '0x11b815efb8f581194ae79006d24e0d814b7697f6'\n","# DECIMAL_0 = 18\n","# DECIMAL_1 = 6\n","# CHUNK_SIZE = 7000\n","\n","# SYMBOL = \"WBTC_USDT\"\n","# POOL_ADDR = '0x9db9e0e53058c89e5b94e29621a205198648425b'\n","# DECIMAL_0 = 8\n","# DECIMAL_1 = 6\n","# CHUNK_SIZE = 50000\n","\n","SYMBOL = \"UNI_USDC\"\n","POOL_ADDR = '0xd0fc8ba7e267f2bc56044a7715a489d851dc6d78'\n","DECIMAL_0 = 18\n","DECIMAL_1 = 6\n","CHUNK_SIZE = 50000\n","\n","START_BLOCK = 13916166\n","END_BLOCK = 16308189\n","\n","\n","bl = START_BLOCK\n","candles = pd.DataFrame()\n","while bl <= END_BLOCK:\n","    chunk_size = min(CHUNK_SIZE,END_BLOCK-bl+1)\n","    print(\"Getting logs from block\",bl,\"to\",bl+chunk_size-1)\n","    logs = getLogs(bl,chunk_size,POOL_ADDR)\n","    print(\"Received\",len(logs), \"tx logs\")\n","    if (len(logs) > 0):\n","      candles = pd.concat([candles,extractPrices(logs,POOL_ADDR,DECIMAL_0,DECIMAL_1)],axis=0)\n","      candles.to_pickle(f'./uni_{SYMBOL}_2022.pkl')\n","    bl += CHUNK_SIZE"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Some Tests\n","\n","# SYMBOL = \"WETH_USDT\"\n","# POOL_ADDR = '0x11b815efb8f581194ae79006d24e0d814b7697f6'\n","# START_BLOCK = 14795022\n","# CHUNK_SIZE = 5000\n","\n","# logs = getLogs(START_BLOCK,5000,POOL_ADDR)\n","# swap_logs = filter_and_decode(logs, POOL_ADDR)\n","# swap_logs = pd.merge(swap_logs, timestamps, left_on='blockNumber', right_on='number', how='left')\n","\n","# swap_logs['price'] = swap_logs['sqrtPriceX96'].apply(lambda price: GetPrice(price,18,6))\n","\n","# swap_logs['datetime'] = pd.to_datetime(swap_logs['timestamp'], unit='s')\n","# swap_logs = swap_logs.set_index('datetime')\n","\n","# swap_logs\n","  \n","# print('Min Price:')\n","# print(swap_logs.loc[swap_logs['price'].idxmin()][['price','txHash','sqrtPriceX96']].to_string())"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# comb = pd.concat([pd.read_pickle(f'./uni_WETH_USDT_2022_1.pkl'), pd.read_pickle(f'./uni_WETH_USDT_2022_2.pkl')])\n","# comb.to_pickle(f'./uni_WETH_USDT_2022.pkl')"]}],"metadata":{"colab":{"provenance":[{"file_id":"1GTFjbgsEYtC8FIfosaI5__xoC2TtyNzV","timestamp":1684163868858}],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.3"}},"nbformat":4,"nbformat_minor":0}
